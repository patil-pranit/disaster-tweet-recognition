{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[[\"text\", \"target\"]]\n",
    "train_df[\"text\"] = train_df[\"text\"].astype(\"str\")\n",
    "# test_df = test_df[[\"text\"]]\n",
    "# test_df = test_df.astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forest fire near La Ronge Sask. Canada'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.target == 1][\"text\"].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data: (7613, 2)\n",
      "shape of test data: (3263, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape of train data: {train_df.shape}\\nshape of test data: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [12,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(\"target\", data=train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(by=[\"target\"]).text.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_sentence(tweet):\n",
    "    tweet_blob = TextBlob(tweet)\n",
    "    print(tweet_blob.words)\n",
    "    return ' '.join(tweet_blob.words)\n",
    "\n",
    "def no_user_alpha(tweet):\n",
    "    tweet_list = [ele for ele in tweet.split() if ele != 'user']\n",
    "    clean_tokens = [t for t in tweet_list if re.match(r'[^\\W\\d]*$', t)]\n",
    "    clean_s = ' '.join(clean_tokens)\n",
    "    clean_mess = [word for word in clean_s.split() if word.lower() not in stopwords.words('english')]\n",
    "    return clean_mess\n",
    "\n",
    "def normalization(tweet_list):\n",
    "    lem = WordNetLemmatizer()\n",
    "    normalized_tweet = []\n",
    "    for word in tweet_list:\n",
    "        normalized_text = lem.lemmatize(word,'v')\n",
    "        normalized_tweet.append(normalized_text)\n",
    "    return normalized_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Three', 'people', 'died', 'from', 'the', 'heat', 'wave', 'so', 'far']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Three people died from the heat wave so far'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "form_sentence(train_df[\"text\"].iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(tweet):\n",
    "    #Generating the list of words in the tweet (hastags and other punctuations removed)\n",
    "    #Generating the list of words in the tweet (hastags and other punctuations removed)\n",
    "    def form_sentence(tweet):\n",
    "        tweet_blob = TextBlob(tweet)\n",
    "        return ' '.join(tweet_blob.words)\n",
    "    new_tweet = form_sentence(tweet)\n",
    "    \n",
    "    #Removing stopwords and words with unusual symbols\n",
    "    def no_user_alpha(tweet):\n",
    "        tweet_list = [ele for ele in tweet.split() if ele != 'user']\n",
    "        clean_tokens = [t for t in tweet_list if re.match(r'[^\\W\\d]*$', t)]\n",
    "        clean_s = ' '.join(clean_tokens)\n",
    "        clean_mess = [word for word in clean_s.split() if word.lower() not in stopwords.words('english')]\n",
    "        return clean_mess\n",
    "    \n",
    "    no_punc_tweet = no_user_alpha(new_tweet)\n",
    "    \n",
    "    #Normalizing the words in tweets \n",
    "    def normalization(tweet_list):\n",
    "        lem = WordNetLemmatizer()\n",
    "        normalized_tweet = []\n",
    "        for word in tweet_list:\n",
    "            normalized_text = lem.lemmatize(word,'v')\n",
    "            normalized_tweet.append(normalized_text)\n",
    "        return normalized_tweet\n",
    "    \n",
    "    \n",
    "    return normalization(no_punc_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"target_list\"] = train_df[\"text\"].apply(text_processing)\n",
    "test_df[\"target_list\"] = test_df[\"text\"].apply(text_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>target_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Deeds, Reason, earthquake, May, ALLAH, Forgiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>[Forest, fire, near, La, Ronge, Sask, Canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[residents, ask, place, notify, officer, evacu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>[people, receive, wildfires, evacuation, order...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[get, send, photo, Ruby, Alaska, smoke, wildfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Two, giant, crane, hold, bridge, collapse, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>[aria_ahrary, TheTawniest, control, wild, fire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>[UTC, Volcano, Hawaii, http]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Police, investigate, collide, car, Little, Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Latest, Homes, Razed, Northern, California, W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3271 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target  \\\n",
       "0     Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1                Forest fire near La Ronge Sask. Canada       1   \n",
       "2     All residents asked to 'shelter in place' are ...       1   \n",
       "3     13,000 people receive #wildfires evacuation or...       1   \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "...                                                 ...     ...   \n",
       "7608  Two giant cranes holding a bridge collapse int...       1   \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1   \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1   \n",
       "7611  Police investigating after an e-bike collided ...       1   \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1   \n",
       "\n",
       "                                            target_list  \n",
       "0     [Deeds, Reason, earthquake, May, ALLAH, Forgiv...  \n",
       "1         [Forest, fire, near, La, Ronge, Sask, Canada]  \n",
       "2     [residents, ask, place, notify, officer, evacu...  \n",
       "3     [people, receive, wildfires, evacuation, order...  \n",
       "4     [get, send, photo, Ruby, Alaska, smoke, wildfi...  \n",
       "...                                                 ...  \n",
       "7608  [Two, giant, crane, hold, bridge, collapse, ne...  \n",
       "7609  [aria_ahrary, TheTawniest, control, wild, fire...  \n",
       "7610                       [UTC, Volcano, Hawaii, http]  \n",
       "7611  [Police, investigate, collide, car, Little, Po...  \n",
       "7612  [Latest, Homes, Razed, Northern, California, W...  \n",
       "\n",
       "[3271 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.target == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Naive Bayes Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_processing)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82      1014\n",
      "           1       0.62      0.80      0.70       509\n",
      "\n",
      "    accuracy                           0.77      1523\n",
      "   macro avg       0.75      0.78      0.76      1523\n",
      "weighted avg       0.80      0.77      0.78      1523\n",
      "\n",
      "[[769 245]\n",
      " [103 406]]\n",
      "0.7715036112934996\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_test, label_train, label_test = train_test_split(train_df['text'], train_df['target'], test_size=0.2)\n",
    "pipeline.fit(msg_train,label_train)\n",
    "predictions = pipeline.predict(msg_test)\n",
    "print(classification_report(predictions,label_test))\n",
    "print(confusion_matrix(predictions,label_test))\n",
    "print(accuracy_score(predictions,label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(test_df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"target\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target_list</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They'd probably still show more life than Arse...</td>\n",
       "      <td>[probably, still, show, life, Arsenal, yesterd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hey! How are you?</td>\n",
       "      <td>[Hey]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What a nice hat?</td>\n",
       "      <td>[nice, hat]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fuck off!</td>\n",
       "      <td>[Fuck]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No I don't like cold!</td>\n",
       "      <td>[like, cold]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>10816</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>@thrillhho jsyk I haven't stopped thinking abt...</td>\n",
       "      <td>[thrillhho, jsyk, stop, think, abt, remus, slu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>10820</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Brussels, Belgium</td>\n",
       "      <td>@stighefootball Begovic has been garbage. He g...</td>\n",
       "      <td>[stighefootball, Begovic, garbage, get, wreck,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>10828</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wrecked today got my hattrick ????</td>\n",
       "      <td>[Wrecked, today, get, hattrick]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>10857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To conference attendees! The blue line from th...</td>\n",
       "      <td>[conference, attendees, blue, line, airport, D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "      <td>[EARTHQUAKE, SAFETY, LOS, ANGELES, SAFETY, FAS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2196 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  keyword           location  \\\n",
       "6        21      NaN                NaN   \n",
       "7        22      NaN                NaN   \n",
       "8        27      NaN                NaN   \n",
       "9        29      NaN                NaN   \n",
       "10       30      NaN                NaN   \n",
       "...     ...      ...                ...   \n",
       "3249  10816  wrecked        los angeles   \n",
       "3250  10820  wrecked  Brussels, Belgium   \n",
       "3251  10828  wrecked                NaN   \n",
       "3256  10857      NaN                NaN   \n",
       "3258  10861      NaN                NaN   \n",
       "\n",
       "                                                   text  \\\n",
       "6     They'd probably still show more life than Arse...   \n",
       "7                                     Hey! How are you?   \n",
       "8                                      What a nice hat?   \n",
       "9                                             Fuck off!   \n",
       "10                                No I don't like cold!   \n",
       "...                                                 ...   \n",
       "3249  @thrillhho jsyk I haven't stopped thinking abt...   \n",
       "3250  @stighefootball Begovic has been garbage. He g...   \n",
       "3251                 Wrecked today got my hattrick ????   \n",
       "3256  To conference attendees! The blue line from th...   \n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...   \n",
       "\n",
       "                                            target_list  target  \n",
       "6     [probably, still, show, life, Arsenal, yesterd...       0  \n",
       "7                                                 [Hey]       0  \n",
       "8                                           [nice, hat]       0  \n",
       "9                                                [Fuck]       0  \n",
       "10                                         [like, cold]       0  \n",
       "...                                                 ...     ...  \n",
       "3249  [thrillhho, jsyk, stop, think, abt, remus, slu...       0  \n",
       "3250  [stighefootball, Begovic, garbage, get, wreck,...       0  \n",
       "3251                    [Wrecked, today, get, hattrick]       0  \n",
       "3256  [conference, attendees, blue, line, airport, D...       0  \n",
       "3258  [EARTHQUAKE, SAFETY, LOS, ANGELES, SAFETY, FAS...       0  \n",
       "\n",
       "[2196 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df.target == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df.target == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_save.to_csv(\"pranit_nlp_submission.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_processing)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       944\n",
      "           1       0.83      0.94      0.88       579\n",
      "\n",
      "    accuracy                           0.90      1523\n",
      "   macro avg       0.89      0.91      0.90      1523\n",
      "weighted avg       0.91      0.90      0.90      1523\n",
      "\n",
      "[[829 115]\n",
      " [ 35 544]]\n",
      "0.9015101772816809\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_test, label_train, label_test = train_test_split(train_df['text'], train_df['target'], test_size=0.2)\n",
    "sgd_pipeline.fit(msg_train,label_train)\n",
    "predictions = pipeline.predict(msg_test)\n",
    "print(classification_report(predictions,label_test))\n",
    "print(confusion_matrix(predictions,label_test))\n",
    "print(accuracy_score(predictions,label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_predictions = sgd_pipeline.predict(test_df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"target\"] = sgd_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    2558\n",
       "1     705\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby(by = [\"target\"]).id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_save = test_df[[\"id\", \"target\"]]\n",
    "sgd_save.to_csv(\"pranit_submission2.csv\", index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target_list</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>[Heard, earthquake, different, cities, stay, s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>[Apocalypse, light, Spokane, wildfires]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We're shaking...It's an earthquake</td>\n",
       "      <td>[shake, earthquake]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They'd probably still show more life than Arse...</td>\n",
       "      <td>[probably, still, show, life, Arsenal, yesterd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hey! How are you?</td>\n",
       "      <td>[Hey]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What a nice hat?</td>\n",
       "      <td>[nice, hat]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fuck off!</td>\n",
       "      <td>[Fuck]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No I don't like cold!</td>\n",
       "      <td>[like, cold]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOOOOOOOOO! Don't do that!</td>\n",
       "      <td>[NOOOOOOOOO]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No don't tell me that!</td>\n",
       "      <td>[tell]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What if?!</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome!</td>\n",
       "      <td>[Awesome]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>46</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>London</td>\n",
       "      <td>Birmingham Wholesale Market is ablaze BBC News...</td>\n",
       "      <td>[Birmingham, Wholesale, Market, ablaze, BBC, N...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>47</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Niall's place | SAF 12 SQUAD |</td>\n",
       "      <td>@sunkxssedharry will you wear shorts for race ...</td>\n",
       "      <td>[sunkxssedharry, wear, short, race, ablaze]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Los Angeles, Califnordia</td>\n",
       "      <td>PSA: IÛªm splitting my personalities.\\n\\n?? t...</td>\n",
       "      <td>[PSA, split, personalities, techies, follow, a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>69</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>threeonefive.</td>\n",
       "      <td>beware world ablaze sierra leone &amp;amp; guap.</td>\n",
       "      <td>[beware, world, ablaze, sierra, leone, amp, guap]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>70</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Washington State</td>\n",
       "      <td>Burning Man Ablaze! by Turban Diva http://t.co...</td>\n",
       "      <td>[Burning, Man, Ablaze, Turban, Diva, http, via...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>72</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Whoop Ass, Georgia</td>\n",
       "      <td>Not a diss song. People will take 1 thing and ...</td>\n",
       "      <td>[diss, song, People, take, thing, run, Smh, ey...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>75</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>India</td>\n",
       "      <td>Rape victim dies as she sets herself ablaze: A...</td>\n",
       "      <td>[Rape, victim, die, set, ablaze, girl, die, bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>84</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SETTING MYSELF ABLAZE http://t.co/6vMe7P5XhC</td>\n",
       "      <td>[SETTING, ABLAZE, http]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword                        location  \\\n",
       "1    2     NaN                             NaN   \n",
       "3    9     NaN                             NaN   \n",
       "5   12     NaN                             NaN   \n",
       "6   21     NaN                             NaN   \n",
       "7   22     NaN                             NaN   \n",
       "8   27     NaN                             NaN   \n",
       "9   29     NaN                             NaN   \n",
       "10  30     NaN                             NaN   \n",
       "11  35     NaN                             NaN   \n",
       "12  42     NaN                             NaN   \n",
       "13  43     NaN                             NaN   \n",
       "14  45     NaN                             NaN   \n",
       "15  46  ablaze                          London   \n",
       "16  47  ablaze  Niall's place | SAF 12 SQUAD |   \n",
       "19  60  ablaze        Los Angeles, Califnordia   \n",
       "20  69  ablaze                  threeonefive.    \n",
       "21  70  ablaze                Washington State   \n",
       "22  72  ablaze              Whoop Ass, Georgia   \n",
       "23  75  ablaze                           India   \n",
       "24  84  ablaze                             NaN   \n",
       "\n",
       "                                                 text  \\\n",
       "1   Heard about #earthquake is different cities, s...   \n",
       "3            Apocalypse lighting. #Spokane #wildfires   \n",
       "5                  We're shaking...It's an earthquake   \n",
       "6   They'd probably still show more life than Arse...   \n",
       "7                                   Hey! How are you?   \n",
       "8                                    What a nice hat?   \n",
       "9                                           Fuck off!   \n",
       "10                              No I don't like cold!   \n",
       "11                         NOOOOOOOOO! Don't do that!   \n",
       "12                             No don't tell me that!   \n",
       "13                                          What if?!   \n",
       "14                                           Awesome!   \n",
       "15  Birmingham Wholesale Market is ablaze BBC News...   \n",
       "16  @sunkxssedharry will you wear shorts for race ...   \n",
       "19  PSA: IÛªm splitting my personalities.\\n\\n?? t...   \n",
       "20       beware world ablaze sierra leone &amp; guap.   \n",
       "21  Burning Man Ablaze! by Turban Diva http://t.co...   \n",
       "22  Not a diss song. People will take 1 thing and ...   \n",
       "23  Rape victim dies as she sets herself ablaze: A...   \n",
       "24       SETTING MYSELF ABLAZE http://t.co/6vMe7P5XhC   \n",
       "\n",
       "                                          target_list  target  \n",
       "1   [Heard, earthquake, different, cities, stay, s...       0  \n",
       "3             [Apocalypse, light, Spokane, wildfires]       0  \n",
       "5                                 [shake, earthquake]       0  \n",
       "6   [probably, still, show, life, Arsenal, yesterd...       0  \n",
       "7                                               [Hey]       0  \n",
       "8                                         [nice, hat]       0  \n",
       "9                                              [Fuck]       0  \n",
       "10                                       [like, cold]       0  \n",
       "11                                       [NOOOOOOOOO]       0  \n",
       "12                                             [tell]       0  \n",
       "13                                                 []       0  \n",
       "14                                          [Awesome]       0  \n",
       "15  [Birmingham, Wholesale, Market, ablaze, BBC, N...       0  \n",
       "16        [sunkxssedharry, wear, short, race, ablaze]       0  \n",
       "19  [PSA, split, personalities, techies, follow, a...       0  \n",
       "20  [beware, world, ablaze, sierra, leone, amp, guap]       0  \n",
       "21  [Burning, Man, Ablaze, Turban, Diva, http, via...       0  \n",
       "22  [diss, song, People, take, thing, run, Smh, ey...       0  \n",
       "23  [Rape, victim, die, set, ablaze, girl, die, bu...       0  \n",
       "24                            [SETTING, ABLAZE, http]       0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df.target == 0].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}